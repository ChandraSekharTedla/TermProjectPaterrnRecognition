{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation and comparision of LSTM(Long Short Term Memory) and ARIMA(Autoregressive integrated moving average) Neural Networks for the application of Stock Price Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from example_functions import fetch_store, split_data, preprocessing_data, invert_scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall follow the following steps to achieve the goal:\n",
    "1. Fetch and store the data(Stock Prices for the past few time intervals).\n",
    "2. Split the data for Training and Testing.\n",
    "3. Processing of data to meet the input criterion of the Neural Network Algorithms.\n",
    "4. Pass the data through LSTM and ARIMA and train the networks.\n",
    "5. Start Predicting the upcoming Stock Prices for the next few time intervals using the 2 models.\n",
    "6. Compare the results of the 2 models and conclude.\n",
    "\n",
    "\n",
    "The following code has all the required functions used by the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\TAMU\\Subjects\\PatternRecognition_ECEN649\\Project\\TermProjectPaterrnRecognition\\src\\additional_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Precprocesses the data for LSTM and ARIMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-i additional_functions.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mprocessed_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessed_test_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaling_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing_data\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\TAMU\\Subjects\\PatternRecognition_ECEN649\\Project\\TermProjectPaterrnRecognition\\src\\additional_functions.py\u001b[0m in \u001b[0;36mpreprocessing_data\u001b[1;34m(train_data, test_data)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# Scaling the data to the range [0, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mprocessed_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mscaling_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mprocessed_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mscaling_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "## Configuration Parameters\n",
    "\n",
    "# Used to divide the data into training set and test set i.e.,\n",
    "# Percentage of Training data in the whole set of data\n",
    "percentage_train_data = 0.65\n",
    "\n",
    "\n",
    "## Step - 1\n",
    "# Fetches and Stores data\n",
    "%run -i additional_functions.py\n",
    "data = fetch_store ()\n",
    "\n",
    "\n",
    "## Step - 2\n",
    "# Splits the data among training and testing\n",
    "%run -i additional_functions.py\n",
    "train_data, test_data = split_data (data, percentage_train_data)\n",
    "\n",
    "\n",
    "## Step - 3\n",
    "# Precprocesses the data for LSTM and ARIMA\n",
    "%run -i additional_functions.py\n",
    "processed_train_data, processed_test_data, scaling_factor = preprocessing_data (train_data, test_data)\n",
    "\n",
    "\n",
    "##"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "780399f4ca915f8b26ba7a4bf43e2f51e62e42691cb13e55fab12f254f8cf844"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
